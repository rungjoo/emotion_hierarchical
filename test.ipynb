{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c934eaba-9455-42cd-8f39-6bee3ce09bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import pdb, os\n",
    "import random\n",
    "from transformers import BertTokenizer\n",
    "    \n",
    "class goemotion_loader(Dataset):\n",
    "    def __init__(self, data_path, model_type, class_type):\n",
    "        f = open(data_path, 'r')\n",
    "        self.datalist = f.readlines()\n",
    "        f.close()\n",
    "        self.class_type = class_type\n",
    "            \n",
    "        model_path = os.path.join('/data/project/rw/rung/model', model_type) # bert-base-cased\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path)  \n",
    "        \n",
    "        f = open('./dataset/emotions.txt', 'r')\n",
    "        self.fineList = f.readlines()\n",
    "        self.fineList = [x.strip() for x in self.fineList]\n",
    "        f.close()        \n",
    "        \n",
    "        with open(\"./dataset/ekman_mapping.json\", 'r') as f:\n",
    "            self.ekman_mapping_data = json.load(f)\n",
    "            self.ekman_mapping_data['neutral'] = ['neutral']\n",
    "            self.ekmanList = list(self.ekman_mapping_data.keys())\n",
    "            self.ekman_reverse_data = {}\n",
    "            for big, small_list in self.ekman_mapping_data.items():\n",
    "                for small in small_list:\n",
    "                    self.ekman_reverse_data[small] = big\n",
    "                    \n",
    "        with open(\"./dataset/sentiment_mapping.json\", 'r') as f:\n",
    "            self.senti_mapping_data = json.load(f)\n",
    "            self.senti_mapping_data['neutral'] = ['neutral']\n",
    "            self.sentiList = list(self.senti_mapping_data.keys())\n",
    "            self.senti_reverse_data = {}\n",
    "            for big, small_list in self.senti_mapping_data.items():\n",
    "                for small in small_list:\n",
    "                    self.senti_reverse_data[small] = big                       \n",
    "        \n",
    "        self.ekmanList = list(self.ekman_mapping_data.keys())\n",
    "        self.sentiList = list(self.senti_mapping_data.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datalist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.datalist[idx]\n",
    "        utt, labels = data.strip().split('\\t')\n",
    "        label_list = labels.split(',')        \n",
    "        \n",
    "        # fine-grained\n",
    "        fine_label_list = [int(x) for x in label_list]\n",
    "        \n",
    "        # ekman & sentiment\n",
    "        ekman_label_list, senti_label_list = [], []\n",
    "        for label in label_list:\n",
    "            emotion = self.fineList[int(label)]\n",
    "            \n",
    "            ekman_emotion = self.ekman_reverse_data[emotion]\n",
    "            ind = self.ekmanList.index(ekman_emotion)\n",
    "            ekman_label_list.append(ind)\n",
    "            \n",
    "            senti_emotion = self.senti_reverse_data[emotion]\n",
    "            ind = self.sentiList.index(senti_emotion)\n",
    "            senti_label_list.append(ind)          \n",
    "            \n",
    "        data = {}\n",
    "        data['utt'] = utt\n",
    "        data['fine_labels'] = fine_label_list\n",
    "        data['ekman_labels'] = ekman_label_list\n",
    "        data['senti_labels'] = senti_label_list\n",
    "        return data\n",
    "    \n",
    "    def encode_truncated(self, text):\n",
    "        max_length = self.tokenizer.model_max_length\n",
    "        tokenized_tokens = self.tokenizer.encode(text, add_special_tokens=False)\n",
    "        truncated_tokens = tokenized_tokens[-max_length:]    \n",
    "\n",
    "        return truncated_tokens  \n",
    "    \n",
    "    def padding(self, ids_list):\n",
    "        max_len = 0\n",
    "        for ids in ids_list:\n",
    "            if len(ids) > max_len:\n",
    "                max_len = len(ids)\n",
    "\n",
    "        pad_ids = []\n",
    "        for ids in ids_list:\n",
    "            pad_len = max_len-len(ids)\n",
    "            add_ids = [self.tokenizer.pad_token_id for _ in range(pad_len)]\n",
    "\n",
    "            pad_ids.append(ids+add_ids)\n",
    "\n",
    "        return torch.tensor(pad_ids)     \n",
    "    \n",
    "    def collate_fn(self, data):\n",
    "        batch_utts = []\n",
    "        fine_batch_labels, ekman_batch_labels, senti_batch_labels = [], [], []\n",
    "        batch = len(data)\n",
    "            \n",
    "        for session in data: \n",
    "            utt = session['utt']\n",
    "            fine_labels, ekman_labels, senti_labels = session['fine_labels'], session['ekman_labels'], session['senti_labels']\n",
    "            \n",
    "            batch_utts.append(utt)\n",
    "            \n",
    "            # fine\n",
    "            fine_batch_label = [0 for _ in range(len(self.fineList))]\n",
    "            for index in fine_labels:\n",
    "                fine_batch_label[index] += 1/len(fine_labels)\n",
    "            fine_batch_labels.append(fine_batch_label)\n",
    "            \n",
    "            # ekman\n",
    "            ekman_batch_label = [0 for _ in range(len(self.ekmanList))]\n",
    "            for index in ekman_labels:\n",
    "                ekman_batch_label[index] += 1/len(ekman_labels)\n",
    "            ekman_batch_labels.append(ekman_batch_label)\n",
    "            \n",
    "            # senti\n",
    "            senti_batch_label = [0 for _ in range(len(self.sentiList))]\n",
    "            for index in senti_labels:\n",
    "                senti_batch_label[index] += 1/len(senti_labels)\n",
    "            senti_batch_labels.append(senti_batch_label)            \n",
    "        \n",
    "        result = self.tokenizer.batch_encode_plus(batch_utts, add_special_tokens=False, padding=True, return_tensors='pt')\n",
    "        batch_input_ids = result['input_ids']\n",
    "        batch_attention_mask = result['attention_mask']\n",
    "        \n",
    "        final_input_ids = torch.cat([torch.tensor([self.tokenizer.cls_token_id for _ in range(batch)]).unsqueeze(1), batch_input_ids], 1)\n",
    "        final_attention_mask = torch.cat([torch.tensor([1 for _ in range(batch)]).unsqueeze(1), batch_input_ids], 1)\n",
    "\n",
    "        return final_input_ids, final_attention_mask, torch.tensor(fine_batch_labels), torch.tensor(ekman_batch_labels), torch.tensor(senti_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "569ca2d1-8b54-411b-82bf-e9a1ccbbd204",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './dataset/train.txt'\n",
    "model_type = 'bert-base-cased'\n",
    "class_type = 'sentiment'#'fine_grained'\n",
    "dataset = goemotion_loader(data_path, model_type, class_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "887eedb8-9162-4edd-85cd-11fa5926c5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utt': \"Aww... she'll probably come around eventually, I'm sure she was just jealous of [NAME]... I mean, what woman wouldn't be! lol \",\n",
       " 'fine_labels': [1, 4],\n",
       " 'ekman_labels': [3, 3],\n",
       " 'senti_labels': [0, 0]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e7d102ff-ae33-4ed8-935e-dd0c8e7be895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "label = 0\n",
    "emotion = dataset.fineList[int(label)]\n",
    "\n",
    "ekman_emotion = dataset.ekman_reverse_data[emotion]\n",
    "ind = dataset.ekmanList.index(ekman_emotion)\n",
    "print(ind)\n",
    "\n",
    "senti_emotion = dataset.senti_reverse_data[emotion]\n",
    "ind = dataset.sentiList.index(senti_emotion)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "24c49beb-b851-4cde-ac5d-357133698db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "senti_emotion = dataset.senti_reverse_data[ekman_emotion]\n",
    "ind = dataset.sentiList.index(senti_emotion)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "061129ab-56b3-4a38-b7e8-7551f3b84e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ekman_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd89ed-de98-4f1e-9614-ed2a092a011c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c6a0b-7179-4d48-94e7-cc348cc5ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a9012-1f30-4075-b249-98e5933946e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba95792e-8d14-4dc8-a151-9d36ac95ce69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"My favourite food is anything I didn't have to cook myself.\",\n",
       " 'Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt1 = dataset[0]['utt']\n",
    "utt2 = dataset[1]['utt']\n",
    "utt1,utt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "89584248-b7d8-436a-b332-257bbdb1f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DataLoader(dataset, batch_size=3, shuffle=True, num_workers=4, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c171775-f35a-4904-9f6e-982223d9eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset_loader:\n",
    "    batch_input_ids, batch_attention_mask, fine_batch_labels, ekman_batch_labels, senti_batch_labels = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39b47745-c6e2-4655-b9d5-c4ebd0ee3802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 17])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ba20905-8a1b-423d-904e-e79d98fb6fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] This is completely false. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] I â€™ m ready to see yet another person fall tonight. [PAD] [PAD] [PAD] [PAD]',\n",
       " \"[CLS] How can they expect you to write if you can't read? / s\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tokenizer.batch_decode(batch_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "abf1edad-5bc6-46a7-a425-d6e85c3d9e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c866fdbb-8ad7-4988-8a13-749773e953c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ekman_batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5efa3ea-de44-418b-87b7-f526e3d5c285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98d750d9-ddd2-4f89-ad3a-e7d54b6788db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['anger', 'annoyance', 'disapproval'],\n",
       " 'disgust': ['disgust'],\n",
       " 'fear': ['fear', 'nervousness'],\n",
       " 'joy': ['joy',\n",
       "  'amusement',\n",
       "  'approval',\n",
       "  'excitement',\n",
       "  'gratitude',\n",
       "  'love',\n",
       "  'optimism',\n",
       "  'relief',\n",
       "  'pride',\n",
       "  'admiration',\n",
       "  'desire',\n",
       "  'caring'],\n",
       " 'sadness': ['sadness', 'disappointment', 'embarrassment', 'grief', 'remorse'],\n",
       " 'surprise': ['surprise', 'realization', 'confusion', 'curiosity'],\n",
       " 'neutral': 'neutral'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49c2b7ed-c113-4a99-887f-beb26910fa85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 'anger',\n",
       " 'annoyance': 'anger',\n",
       " 'disapproval': 'anger',\n",
       " 'disgust': 'disgust',\n",
       " 'fear': 'fear',\n",
       " 'nervousness': 'fear',\n",
       " 'joy': 'joy',\n",
       " 'amusement': 'joy',\n",
       " 'approval': 'joy',\n",
       " 'excitement': 'joy',\n",
       " 'gratitude': 'joy',\n",
       " 'love': 'joy',\n",
       " 'optimism': 'joy',\n",
       " 'relief': 'joy',\n",
       " 'pride': 'joy',\n",
       " 'admiration': 'joy',\n",
       " 'desire': 'joy',\n",
       " 'caring': 'joy',\n",
       " 'sadness': 'sadness',\n",
       " 'disappointment': 'sadness',\n",
       " 'embarrassment': 'sadness',\n",
       " 'grief': 'sadness',\n",
       " 'remorse': 'sadness',\n",
       " 'surprise': 'surprise',\n",
       " 'realization': 'surprise',\n",
       " 'confusion': 'surprise',\n",
       " 'curiosity': 'surprise'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16fc0e59-75c2-4ef1-9cfa-b20309df67ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mapping_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6de5d4-37a9-4a08-8703-1e9bf0cca41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "812a6520-0c39-4a2c-9736-f598d87aa50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os, sys\n",
    "import pdb\n",
    "\n",
    "class EmoModel(nn.Module):\n",
    "    def __init__(self, model_type):\n",
    "        super(EmoModel, self).__init__()        \n",
    "        \n",
    "        model_path = os.path.join('/data/project/rw/rung/model', model_type)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "        self.model = BertModel.from_pretrained(model_path)\n",
    "        \n",
    "        f = open('./dataset/emotions.txt', 'r')\n",
    "        self.emoList = f.readlines()\n",
    "        f.close()\n",
    "        self.clsNum = len(self.emoList)        \n",
    "        \n",
    "        self.Wc = nn.Linear(self.model.config.hidden_size, self.clsNum) # for classification\n",
    "\n",
    "    def forward(self, batch_input_ids, batch_attention_mask):\n",
    "        \"\"\"\n",
    "            input_tokens: (batch, len)\n",
    "        \"\"\"\n",
    "        hidden_outs = self.model(batch_input_ids, attention_mask=batch_attention_mask)['last_hidden_state'] # [B, L, 768]\n",
    "        pred_outs = self.Wc(hidden_outs) # (B, L, C)\n",
    "        cls_outs = pred_outs[:,0,:] # (B, C)\n",
    "        return cls_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "317ff259-6642-415a-8eeb-3ee0c505ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmoModel(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d9ce7a6-758f-4f15-a21f-7d63d2b27c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits = model(batch_input_ids, batch_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc53397d-bb57-4910-ad86-10cc751f6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "pred_distribution = softmax(pred_logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a0cc78d-a3d2-49c2-b746-e0890a4dbed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 28]), torch.Size([3, 28]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_distribution.shape, batch_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1109bb-038a-4d2b-aa6b-8764a32ba327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdloss(batch_pred_distribution, batch_label_distribution):\n",
    "    \"\"\"\n",
    "    batch_pred_distribution: (batch, clsNum)\n",
    "    batch_label_distribution: (batch, clsNum)\n",
    "    \"\"\"\n",
    "    batch_log_pred_distribution = torch.log(batch_pred_distribution)\n",
    "    \n",
    "    loss_val = 0\n",
    "    for log_pred_distribution, label_distribution in zip(batch_log_pred_distribution, batch_label_distribution):\n",
    "        for log_pred_prob, label_prob in zip(log_pred_distribution, label_distribution):\n",
    "            loss_val -= label_prob*log_pred_prob\n",
    "    return loss_val/len(batch_pred_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48f9ed23-2611-4480-829c-d2772aebc547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6069, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdloss(pred_distribution, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d81cc7fd-07e7-4814-bcdd-7a2324453ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083bed4-68ed-4149-8357-54fdd3d9d93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb869b8-8ffb-44e4-8101-9863b7e5610c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a70d1373-e096-45ef-bc20-c5b7306cf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4, collate_fn=dataset.collate_fn)\n",
    "for data in dataset_loader:\n",
    "    batch_input_ids, batch_attention_mask, batch_labels = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee42f836-dd4c-49b1-8df2-7167b42f58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits = model(batch_input_ids, batch_attention_mask)\n",
    "from torch.nn.functional import softmax\n",
    "pred_distribution = softmax(pred_logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "276647ff-a4d7-4269-b8c0-d1a4ee36ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sort = pred_distribution.sort(descending=True)\n",
    "indices = pred_sort.indices.tolist()[0]\n",
    "\n",
    "pred_label = indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd0bb09f-7205-4a6b-b9ec-7adbfa5a8799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bca5a45a-1836-4f2e-a4ca-826e9db87aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0404, 0.0450, 0.0329, 0.0485, 0.0454, 0.0178, 0.0199, 0.0377, 0.0362,\n",
       "         0.0579, 0.0449, 0.0357, 0.0462, 0.0288, 0.0341, 0.0326, 0.0328, 0.0323,\n",
       "         0.0225, 0.0298, 0.0489, 0.0316, 0.0451, 0.0173, 0.0156, 0.0262, 0.0400,\n",
       "         0.0540]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6d4b701-4ae8-4ac2-9fbd-384138e96fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "for ind, label in enumerate(batch_labels.squeeze(0)):\n",
    "    if label > 0:\n",
    "        print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25582196-fb10-45b7-b614-76614efee304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./dataset/ekman_mapping.json', 'r') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f82a70c9-2e5e-4749-a79b-26e24b91eeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913d08e-b805-4c0b-9df5-d0b68347630e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c95ad9-5828-41d3-bf4f-3baf86114a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a5c3000-371e-4c7f-875f-a92d4f92e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_indices = [0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1]\n",
    "batch_labels = torch.tensor([[1., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64239faf-a78a-434e-852d-a1560383db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = pred_indices[0] # pred_logits.argmax(1).item()            \n",
    "true_labels = []\n",
    "for ind, label in enumerate(batch_labels.squeeze(0)):\n",
    "    if label > 0:\n",
    "        true_labels.append(ind)\n",
    "\n",
    "\"\"\"Calculation precision@k and recall@k\"\"\"\n",
    "p1, p2, p3 = 0, 0, 0\n",
    "r1, r2, r3 = 0, 0, 0\n",
    "\n",
    "for pred_ind in pred_indices[:1]:\n",
    "    if pred_ind in true_labels:\n",
    "        p1 += 1\n",
    "        r1 += 1/len(true_labels)\n",
    "\n",
    "for pred_ind in pred_indices[:2]:\n",
    "    if pred_ind in true_labels:\n",
    "        p2 += 1/2\n",
    "        r2 += 1/len(true_labels)\n",
    "\n",
    "for pred_ind in pred_indices[:3]:\n",
    "    if pred_ind in true_labels:\n",
    "        p3 += 1/3\n",
    "        r3 += 1/len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "50a9121b-360d-4821-b390-1ca99f5ce8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df831d-6611-42c8-a023-939c5d3a3ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
